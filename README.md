# GUIÃ“N DE PRESENTACIÃ“N - MINERÃA DE DATOS 2025

## Autor
- **Javier FarÃ­as**

Universidad AndrÃ©s Bello - IngenierÃ­a Civil InformÃ¡tica

---

## ESTRUCTURA DE LA PRESENTACIÃ“N
---

## ğŸ“‹ ORDEN DE PESTAÃ‘AS

### 1. ğŸ  INICIO (~1 minuto)
- Saludar y presentarse
- Describir brevemente el proyecto: "PredicciÃ³n de congestiÃ³n vehicular en Santiago usando Machine Learning"
- Destacar los 3 KPIs: 10,000 observaciones, 5 algoritmos, K-NN ganador

**QuÃ© decir:**
> "Buenos dÃ­as. Soy Javier FarÃ­as, estudiante de IngenierÃ­a Civil InformÃ¡tica de la Universidad AndrÃ©s Bello. Hoy presento mi proyecto de minerÃ­a de datos: un anÃ¡lisis de Machine Learning para predecir la duraciÃ³n de congestiÃ³n vehicular en Santiago."

---

### 2. ğŸ“š MARCO TEÃ“RICO (~2 minutos)
- Explicar quÃ© es el aprendizaje supervisado (datos etiquetados)
- Diferencia entre clasificaciÃ³n y regresiÃ³n
- Describir los 5 algoritmos utilizados brevemente
- Mencionar que K-NN fue el ganador

**QuÃ© decir:**
> "El aprendizaje supervisado entrena modelos con datos etiquetados. Puede ser clasificaciÃ³n para categorÃ­as o regresiÃ³n para valores continuos. UsÃ© regresiÃ³n porque predigo horas de congestiÃ³n. ComparÃ© 5 algoritmos: regresiÃ³n lineal, Ã¡rboles de decisiÃ³n, redes neuronales, SVM y K-NN."

---

### 3. ğŸ¯ OBJETIVOS Y VARIABLES (~1.5 minutos)
- Objetivo: predecir duraciÃ³n de congestiÃ³n con precisiÃ³n
- Variable dependiente: Duration_hrs (118 valores Ãºnicos)
- Variables independientes: geogrÃ¡ficas, infraestructura, trÃ¡fico
- JustificaciÃ³n de REGRESIÃ“N: variable continua

**QuÃ© decir:**
> "Mi objetivo es predecir la duraciÃ³n de congestiÃ³n. La variable objetivo es Duration_hrs con 118 valores Ãºnicos, por eso elegÃ­ regresiÃ³n. UsÃ© 24 features incluyendo longitud del trayecto, comuna y coordenadas."

---

### 4. â±ï¸ TIEMPOS DE ENTRENAMIENTO (~1 minuto)
- Mostrar los 3 value boxes (tiempo total, mÃ¡s rÃ¡pido, mÃ¡s lento)
- Explicar que usÃ© 3-fold cross-validation
- Mencionar que SVM fue el mÃ¡s lento

**QuÃ© decir:**
> "El entrenamiento total tomÃ³ aproximadamente 33 segundos. El Ã¡rbol de decisiÃ³n fue el mÃ¡s rÃ¡pido, mientras que SVM fue el mÃ¡s lento debido a su complejidad computacional."

---

### 5. ğŸ“ˆ REGRESIÃ“N LINEAL (~1 minuto)
- Mostrar tabla de coeficientes
- Explicar interpretaciÃ³n: positivo aumenta, negativo disminuye

**QuÃ© decir:**
> "La regresiÃ³n lineal permite interpretar los coeficientes. Los valores positivos aumentan la duraciÃ³n de congestiÃ³n, los negativos la disminuyen."

---

### 6. ğŸŒ³ ÃRBOL DE DECISIÃ“N (~1 minuto)
- Mostrar visualizaciÃ³n del Ã¡rbol
- Explicar que cada nodo es una decisiÃ³n

**QuÃ© decir:**
> "El Ã¡rbol de decisiÃ³n muestra cÃ³mo el modelo toma decisiones mediante reglas tipo si-entonces."

---

### 7. ğŸ§  RED NEURONAL (~1 minuto)
- Mostrar arquitectura de la red
- Explicar las 3 capas: entrada (24), oculta (3-5), salida (1)

**QuÃ© decir:**
> "La red neuronal tiene 24 neuronas de entrada, una capa oculta optimizada por validaciÃ³n cruzada, y una neurona de salida para la predicciÃ³n."

---

### 8. ğŸ“Š COMPARACIÃ“N DE MODELOS (~1.5 minutos)
- Mostrar grÃ¡fico de barras con RMSE
- Destacar que K-NN tiene menor RMSE (0.9348)
- Mostrar tabla con mÃ©tricas

**QuÃ© decir:**
> "AquÃ­ vemos la comparaciÃ³n de todos los modelos. K-NN obtuvo el mejor RMSE con 0.9348 horas, seguido de cerca por la red neuronal."

---

### 9. âœ… VALIDACIÃ“N EN TEST (~1.5 minutos)
- Mostrar los 4 value boxes del modelo ganador
- Destacar MAE de 31 minutos como mÃ©trica interpretable
- Explicar por quÃ© K-NN ganÃ³

**QuÃ© decir:**
> "Estas mÃ©tricas fueron calculadas en el conjunto de prueba, datos nunca vistos durante el entrenamiento. K-NN logra un error promedio de 31 minutos. GanÃ³ porque captura patrones locales del trÃ¡fico santiaguino."

---

### 10. ğŸ“‰ ANÃLISIS DE RESIDUALES (~1 minuto)
- Mostrar grÃ¡fico de residuales
- Mostrar importancia de variables
- Destacar top 3: Length_km, Commune_Santiago, Longitud

**QuÃ© decir:**
> "Las variables mÃ¡s importantes son la longitud del trayecto, la comuna de Santiago y la coordenada de longitud, lo que tiene sentido geogrÃ¡ficamente."

---

### 11. ğŸ† CONCLUSIONES (~1.5 minutos)
- Modelo ganador: K-NN con error de 31 minutos
- Variables clave
- Limitaciones y mejoras futuras

**QuÃ© decir:**
> "En conclusiÃ³n, K-NN es el modelo ganador con un error promedio de 31 minutos. El trÃ¡fico de Santiago tiene patrones locales que este algoritmo captura bien. Como mejoras futuras propongo incorporar datos de clima y usar el dataset completo."

---

### 12. ğŸ“– REFERENCIAS (~30 segundos)
- Mencionar las fuentes principales
- Destacar el repositorio de GitHub

**Cierre:**
> "Las referencias incluyen textos clÃ¡sicos de Machine Learning y datos del Ministerio de Transportes. Todo el cÃ³digo estÃ¡ en GitHub. Â¿Tienen preguntas?"

---

## ğŸ“‹ RESUMEN

| PestaÃ±a | Tiempo |
|---------|--------|
| ğŸ  Inicio | ~1 min |
| ğŸ“š Marco TeÃ³rico | ~2 min |
| ğŸ¯ Objetivos y Variables | ~1.5 min |
| â±ï¸ Tiempos | ~1 min |
| ğŸ“ˆ RegresiÃ³n Lineal | ~1 min |
| ğŸŒ³ Ãrbol de DecisiÃ³n | ~1 min |
| ğŸ§  Red Neuronal | ~1 min |
| ğŸ“Š ComparaciÃ³n | ~1.5 min |
| âœ… ValidaciÃ³n | ~1.5 min |
| ğŸ“‰ Residuales | ~1 min |
| ğŸ† Conclusiones | ~1.5 min |
| ğŸ“– Referencias | ~0.5 min |

**Total: ~13 minutos**

---

## ğŸš€ COMANDO PARA EJECUTAR LOCALMENTE

```r
Rscript -e "shiny::runApp('app.R', launch.browser = TRUE)"
```

---

