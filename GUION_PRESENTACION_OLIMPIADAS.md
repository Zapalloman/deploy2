# GUIÃ“N DE PRESENTACIÃ“N - OLIMPIADAS CIENCIA DE DATOS 2025

## Equipo
- **Javier FarÃ­as**
- **Uriel Navarrete**

Universidad AndrÃ©s Bello - IngenierÃ­a Civil InformÃ¡tica

---

## DISTRIBUCIÃ“N DEL CONTENIDO

### â±ï¸ TIEMPO TOTAL: ~12-15 minutos

---

## ğŸ‘¤ JAVIER FARÃAS (Primera mitad: ~6-7 minutos)

### PestaÃ±as a presentar:

#### 1. ğŸ  INICIO (~1 minuto)
- Saludar y presentar al equipo
- Mencionar que ganamos las olimpiadas regionales
- Describir brevemente el proyecto: "PredicciÃ³n de congestiÃ³n vehicular en Santiago usando Machine Learning"
- Destacar los 3 KPIs: 10,000 observaciones, 5 algoritmos, K-NN ganador

**QuÃ© decir:**
> "Buenos dÃ­as. Somos Javier FarÃ­as y Uriel Navarrete, estudiantes de IngenierÃ­a Civil InformÃ¡tica de la Universidad AndrÃ©s Bello. Hoy presentamos nuestro proyecto ganador de las olimpiadas de ciencia de datos: un anÃ¡lisis de Machine Learning para predecir la duraciÃ³n de congestiÃ³n vehicular en Santiago."

---

#### 2. ğŸ“š MARCO TEÃ“RICO (~2 minutos)
- Explicar quÃ© es el aprendizaje supervisado (datos etiquetados)
- Diferencia entre clasificaciÃ³n y regresiÃ³n
- Describir los 5 algoritmos utilizados:
  1. RegresiÃ³n Lineal â†’ baseline
  2. Ãrbol de DecisiÃ³n â†’ captura no linealidades
  3. Red Neuronal â†’ aproximador universal
  4. SVM-Îµ â†’ robusto a outliers
  5. K-NN â†’ patrones locales
- Mencionar que K-NN fue el ganador

**QuÃ© decir:**
> "El aprendizaje supervisado entrena modelos con datos etiquetados. Puede ser clasificaciÃ³n para categorÃ­as o regresiÃ³n para valores continuos. Nosotros usamos regresiÃ³n porque predecimos horas de congestiÃ³n. Comparamos 5 algoritmos: regresiÃ³n lineal como baseline, Ã¡rboles de decisiÃ³n para capturar no linealidades, redes neuronales, SVM y K-NN. Adelanto que K-NN resultÃ³ ganador."

---

#### 3. ğŸ¯ OBJETIVOS Y VARIABLES (~1.5 minutos)
- Objetivo: predecir duraciÃ³n de congestiÃ³n con precisiÃ³n
- Variable dependiente: Duration_hrs (118 valores Ãºnicos)
- Variables independientes: geogrÃ¡ficas, infraestructura, trÃ¡fico
- JustificaciÃ³n de REGRESIÃ“N: variable continua, muchos valores Ãºnicos

**QuÃ© decir:**
> "Nuestro objetivo es predecir la duraciÃ³n de congestiÃ³n. La variable objetivo es Duration_hrs, que tiene 118 valores Ãºnicos, por eso elegimos regresiÃ³n y no clasificaciÃ³n. Usamos 24 features que incluyen longitud del trayecto, comuna, coordenadas y velocidad."

---

#### 4. â±ï¸ TIEMPOS DE ENTRENAMIENTO (~1 minuto)
- Mostrar los 3 value boxes (tiempo total, mÃ¡s rÃ¡pido, mÃ¡s lento)
- Explicar que usamos 3-fold cross-validation
- Mostrar grÃ¡fico de tiempos
- Mencionar que SVM fue el mÃ¡s lento (28 segundos)

**QuÃ© decir:**
> "El entrenamiento total tomÃ³ aproximadamente 33 segundos. El Ã¡rbol de decisiÃ³n fue el mÃ¡s rÃ¡pido con 0.3 segundos, mientras que SVM fue el mÃ¡s lento con 28 segundos debido a su complejidad computacional."

---

#### 5. ğŸ“ˆ REGRESIÃ“N LINEAL (~1 minuto)
- Mostrar tabla de coeficientes
- Explicar interpretaciÃ³n: positivo aumenta, negativo disminuye
- Destacar variables con mayor coeficiente

**QuÃ© decir:**
> "La regresiÃ³n lineal nos permite interpretar los coeficientes. Los valores positivos aumentan la duraciÃ³n de congestiÃ³n, los negativos la disminuyen. Vemos que la longitud del trayecto tiene gran impacto, como era de esperar."

---

#### 6. ğŸŒ³ ÃRBOL DE DECISIÃ“N (~1 minuto)
- Mostrar visualizaciÃ³n del Ã¡rbol
- Explicar que cada nodo es una decisiÃ³n
- Mencionar que es fÃ¡cil de interpretar

**TransiciÃ³n a Uriel:**
> "El Ã¡rbol de decisiÃ³n nos muestra cÃ³mo el modelo toma decisiones mediante reglas tipo si-entonces. Ahora Uriel continuarÃ¡ con los modelos mÃ¡s avanzados y las conclusiones."

---

## ğŸ‘¤ URIEL NAVARRETE (Segunda mitad: ~6-7 minutos)

### PestaÃ±as a presentar:

#### 7. ğŸ§  RED NEURONAL (~1 minuto)
- Mostrar arquitectura de la red
- Explicar las 3 capas: entrada (24), oculta (3-5), salida (1)
- Mencionar configuraciÃ³n: nnet con linout=TRUE, decay=0.1

**QuÃ© decir:**
> "Gracias Javier. Continuamos con la red neuronal. Tiene 24 neuronas de entrada correspondientes a nuestras features, una capa oculta de 3 a 5 neuronas optimizada por validaciÃ³n cruzada, y una neurona de salida que produce la predicciÃ³n de duraciÃ³n."

---

#### 8. ğŸ“Š COMPARACIÃ“N DE MODELOS (~1.5 minutos)
- Mostrar grÃ¡fico de barras con RMSE
- Destacar que K-NN tiene menor RMSE (0.9348)
- Mostrar tabla con todas las mÃ©tricas e hiperparÃ¡metros
- Explicar brevemente cada mÃ©trica

**QuÃ© decir:**
> "AquÃ­ vemos la comparaciÃ³n de todos los modelos. K-NN obtuvo el mejor RMSE con 0.9348 horas, seguido de cerca por la red neuronal. La tabla muestra los hiperparÃ¡metros Ã³ptimos encontrados para cada modelo mediante validaciÃ³n cruzada."

---

#### 9. âœ… VALIDACIÃ“N EN TEST (~1.5 minutos)
- Mostrar los 4 value boxes del modelo ganador
- Explicar que el test set nunca fue visto durante entrenamiento
- Destacar MAE de 31 minutos como mÃ©trica interpretable
- Explicar por quÃ© K-NN ganÃ³: patrones locales

**QuÃ© decir:**
> "Estas mÃ©tricas fueron calculadas en el conjunto de prueba, datos nunca vistos durante el entrenamiento. K-NN logra un error promedio de 31 minutos, que es bastante Ãºtil para planificaciÃ³n. GanÃ³ porque captura patrones locales del trÃ¡fico santiaguino sin asumir relaciones globales."

---

#### 10. ğŸ“‰ ANÃLISIS DE RESIDUALES (~1 minuto)
- Mostrar grÃ¡fico de residuales
- Explicar que puntos cercanos a diagonal son buenas predicciones
- Mostrar importancia de variables
- Destacar top 3: Length_km, Commune_Santiago, Longitud

**QuÃ© decir:**
> "El grÃ¡fico de residuales muestra que las predicciones estÃ¡n bastante centradas. Las variables mÃ¡s importantes son la longitud del trayecto, la comuna de Santiago y la coordenada de longitud, lo que tiene sentido geogrÃ¡ficamente."

---

#### 11. ğŸ† CONCLUSIONES (~1.5 minutos)
- Modelo ganador: K-NN con error de 31 minutos
- Hallazgo principal: trÃ¡fico tiene patrones locales
- Variables clave: Length_km, Commune, Longitud
- Aplicaciones prÃ¡cticas: planificaciÃ³n urbana, informaciÃ³n ciudadana
- Deficiencias: RÂ² bajo (20.6%), dataset reducido
- Mejoras futuras: mÃ¡s variables (clima), dataset completo, ensemble methods

**QuÃ© decir:**
> "En conclusiÃ³n, K-NN es el modelo ganador con un error promedio de 31 minutos. El trÃ¡fico de Santiago tiene patrones locales fuertes que este algoritmo captura bien. Aunque el RÂ² de 20.6% es modesto, es razonable para trÃ¡fico urbano que tiene componentes aleatorios. Como mejoras futuras proponemos incorporar datos de clima y eventos."

---

#### 12. ğŸ“– REFERENCIAS (~30 segundos)
- Mencionar las fuentes principales
- Destacar el repositorio de GitHub

**Cierre:**
> "Las referencias incluyen textos clÃ¡sicos como 'Introduction to Statistical Learning' y datos oficiales del Ministerio de Transportes. Todo el cÃ³digo estÃ¡ disponible en nuestro repositorio de GitHub. Â¿Tienen preguntas?"

---

## ğŸ“‹ RESUMEN DE DISTRIBUCIÃ“N

| PestaÃ±a | Presentador | Tiempo |
|---------|-------------|--------|
| ğŸ  Inicio | Javier | ~1 min |
| ğŸ“š Marco TeÃ³rico | Javier | ~2 min |
| ğŸ¯ Objetivos y Variables | Javier | ~1.5 min |
| â±ï¸ Tiempos | Javier | ~1 min |
| ğŸ“ˆ RegresiÃ³n Lineal | Javier | ~1 min |
| ğŸŒ³ Ãrbol de DecisiÃ³n | Javier | ~1 min |
| ğŸ§  Red Neuronal | Uriel | ~1 min |
| ğŸ“Š ComparaciÃ³n | Uriel | ~1.5 min |
| âœ… ValidaciÃ³n | Uriel | ~1.5 min |
| ğŸ“‰ Residuales | Uriel | ~1 min |
| ğŸ† Conclusiones | Uriel | ~1.5 min |
| ğŸ“– Referencias | Uriel | ~0.5 min |

**Total: ~13 minutos**

---

## ğŸ¯ TIPS PARA LA PRESENTACIÃ“N

### Antes de empezar:
- [ ] Tener el dashboard abierto en: https://zapallo.shinyapps.io/congestion-santiago-ml/ (o ejecutar `app_olimpiadas.R` localmente)
- [ ] Probar los botones "â† Anterior" y "Siguiente â†’" para navegaciÃ³n fluida
- [ ] Tener el cÃ³digo abierto en VSCode por si hay preguntas tÃ©cnicas

### Durante la presentaciÃ³n:
- Usar los botones de navegaciÃ³n del sidebar para cambiar de pestaÃ±a fluidamente
- Hacer zoom en los grÃ¡ficos interactivos para destacar puntos importantes
- Aprovechar los tooltips de Plotly para mostrar valores exactos

### Para las preguntas:
- **Javier:** Preguntas sobre teorÃ­a, algoritmos, metodologÃ­a
- **Uriel:** Preguntas sobre resultados, conclusiones, cÃ³digo

### Si algo falla:
- Backup local: `Rscript -e "shiny::runApp('app_olimpiadas.R')"`
- Screenshots en carpeta de respaldo

---

## ğŸš€ COMANDO PARA EJECUTAR

```r
# OpciÃ³n 1: Ejecutar localmente
Rscript -e "shiny::runApp('app_olimpiadas.R', launch.browser = TRUE)"

# OpciÃ³n 2: Desplegar a ShinyApps.io
rsconnect::deployApp(appDir = ".", appPrimaryDoc = "app_olimpiadas.R", appName = "olimpiadas-congestion-ml")
```

---

**Â¡Ã‰xito en la presentaciÃ³n final! ğŸ†**
